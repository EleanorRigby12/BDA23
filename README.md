# BDA23

The purpose of this project is to learn and practice various applications we’ve learned during the Technion Big Data Analysis Course (BDA23)
We have used the famous Churn dataset which contains customers and attributes and whatever they have churned

##########################

The Project consist of three parts:

Part A – Python:
Perform EDA & Prep of the Churn dataset
Investigate the data, look for trends & insights from the dataset
Divide the original churn dataset into test & train sets, and evaluate 3 ML Algorithms
Identify their best hyperparameters to achieve the best accuracy
Decide which of them gives the best result

Part B – MongoDB:
Use MongoDB to import json file contains 25K new rows
Filter the desired big data using MQL query and create Dataframe
Analyze the scheme using MongoDB Compass, clean and adjust the problematic columns
Use the original Churn dataset as train data, while the new data is the test data
Use the best model from Part A to predict churn 

Part D – Tableau Prep & Desktop:
Using Tableau Prep create Star scheme model and create hyper files
Clean and prep the data – handle nulls, duplicates etc
Using Tableau Desktop create reports & dashboards 




##########################
###       Files:       ###
##########################

Project python files were created with the following concept:

1) Churn_functions.py – Functions for churn prep, split, using algorithm and saving results 
2) MongoDB_prep.py – Functions for MongoDB connection, MQL and Data prep
3) Main.py – Running all functions
4) Project Presentation (Powerpoint)
5) Tableau Prep file
6) 4 x Tableau Hyper files
7) Tableau Desktop file
   


